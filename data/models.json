{
  "models": [
    {
      "name": "mistral-7b-v0.3",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32768,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.5,
        "mmlu_pro": null,
        "humaneval": 38.4,
        "gsm8k": 52.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/mistral-7b-v0.3-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-0.6B",
      "total_params_b": 0.6,
      "active_params_b": 0.6,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-0.6B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gpt-oss-20b-BF16",
      "total_params_b": 20.0,
      "active_params_b": 2.5,
      "is_moe": true,
      "num_experts": 32,
      "num_active_experts": 4,
      "hidden_dim": 2880,
      "num_layers": 24,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 201088,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gpt-oss-20b-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-8B-Instruct",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-8B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Meta-Llama-3.1-8B-Instruct",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-8B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "llava-1.5-7b-hf",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 32064,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/llava-1.5-7b-hf-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-4B-Thinking",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-4B-Thinking-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Devstral-Small-2-24B-Instruct-2512",
      "total_params_b": 24.0,
      "active_params_b": 24.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 393216,
      "effective_context_length": 393216,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 24.0,
        "humaneval": 79.9,
        "gsm8k": null,
        "math": 10.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gpt-oss-20b",
      "total_params_b": 20.0,
      "active_params_b": 2.5,
      "is_moe": true,
      "num_experts": 32,
      "num_active_experts": 4,
      "hidden_dim": 2880,
      "num_layers": 24,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 201088,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 1.8,
        "humaneval": 7.9,
        "gsm8k": null,
        "math": 1.1,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gpt-oss-20b-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-27b-it",
      "total_params_b": 27.0,
      "active_params_b": 27.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5376,
      "num_layers": 62,
      "num_heads": 32,
      "num_kv_heads": 16,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-27b-it-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-1.7B",
      "total_params_b": 1.7,
      "active_params_b": 1.7,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-1.7B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-4b-it",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 34,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-4b-it",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-1.5B",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 65.9,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "llama-3-8b-Instruct",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 61.6,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/llama-3-8b-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-4B",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-4B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-1B-Instruct",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 49.3,
        "mmlu_pro": 24.7,
        "humaneval": 43.3,
        "gsm8k": 44.4,
        "math": 30.6,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-1B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gpt-oss-120b",
      "total_params_b": 120.0,
      "active_params_b": 3.75,
      "is_moe": true,
      "num_experts": 128,
      "num_active_experts": 4,
      "hidden_dim": 2880,
      "num_layers": 36,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 201088,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 1.8,
        "humaneval": 7.9,
        "gsm8k": null,
        "math": 1.1,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gpt-oss-120b-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Pixtral-12B-2409",
      "total_params_b": 12.0,
      "active_params_b": 12.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 1024000,
      "effective_context_length": 1024000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 38.7,
        "humaneval": 76.2,
        "gsm8k": null,
        "math": 18.7,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Pixtral-12B-2409-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-Next-80B-A3B-Instruct",
      "total_params_b": 80.0,
      "active_params_b": 80.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-Next-80B-A3B-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-3B-Instruct",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 63.4,
        "mmlu_pro": 37.3,
        "humaneval": 61.6,
        "gsm8k": 77.7,
        "math": 48.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-3B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-12b-it",
      "total_params_b": 12.0,
      "active_params_b": 12.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3840,
      "num_layers": 48,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 4.1,
        "humaneval": 25.0,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-12b-it-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-14B",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-14B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-7B-Instruct",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 68.0,
        "mmlu_pro": null,
        "humaneval": 88.4,
        "gsm8k": 80.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-7B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.1-BF16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 81.1,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.1-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Nemotron-3-Nano-30B-A3B",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2688,
      "num_layers": 52,
      "num_heads": 32,
      "num_kv_heads": 2,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Nemotron-3-Nano-30B-A3B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-4B-Instruct-2507",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-4B-Instruct-2507-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-14B-Instruct",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 79.0,
        "mmlu_pro": 55.0,
        "humaneval": 80.0,
        "gsm8k": 90.0,
        "math": 62.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-14B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "orpheus-3b-0.1-ft",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 156940,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/orpheus-3b-0.1-ft-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "llama-3-8b",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 61.6,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/llama-3-8b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-8B-Instruct",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-30B-A3B",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-30B-A3B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-VL-7B-Instruct",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-VL-7B-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-7B-Instruct",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 74.0,
        "mmlu_pro": 50.0,
        "humaneval": 75.0,
        "gsm8k": 85.0,
        "math": 55.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-270m-it",
      "total_params_b": 0.26,
      "active_params_b": 0.26,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 640,
      "num_layers": 18,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-270m-it",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Meta-Llama-3.1-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Meta-Llama-3.1-8B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-3B-Instruct",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 66.0,
        "mmlu_pro": null,
        "humaneval": 56.7,
        "gsm8k": 75.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-3B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3-0324-BF16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 91.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3-0324-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-4B-Base",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-4B-Base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "mistral-7b-instruct-v0.3",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32768,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.5,
        "mmlu_pro": null,
        "humaneval": 38.4,
        "gsm8k": 52.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/mistral-7b-instruct-v0.3-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-0528-Qwen3-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-1b-it",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1152,
      "num_layers": 26,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-1b-it-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-Coder-30B-A3B-Instruct",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-1.5B-Instruct",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-1.5B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Phi-3-mini-4k-instruct",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 32064,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 68.8,
        "mmlu_pro": null,
        "humaneval": 58.5,
        "gsm8k": 82.5,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Phi-3-mini-4k-instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-32B",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-32B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-12b-it-qat-int4",
      "total_params_b": 12.0,
      "active_params_b": 12.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3840,
      "num_layers": 48,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-12b-it-qat-int4-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gpt-oss-120b-BF16",
      "total_params_b": 120.0,
      "active_params_b": 3.75,
      "is_moe": true,
      "num_experts": 128,
      "num_active_experts": 4,
      "hidden_dim": 2880,
      "num_layers": 36,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 201088,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gpt-oss-120b-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Small-24B-Instruct-2501",
      "total_params_b": 24.0,
      "active_params_b": 24.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 38.7,
        "humaneval": 76.2,
        "gsm8k": null,
        "math": 18.7,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Small-24B-Instruct-2501",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "meta-Llama-3.1-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/meta-Llama-3.1-8B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Small-3.1-24B-Instruct-2503",
      "total_params_b": 24.0,
      "active_params_b": 24.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Small-3.1-24B-Instruct-2503",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-OCR",
      "total_params_b": 0.4,
      "active_params_b": 0.4,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1280,
      "num_layers": 12,
      "num_heads": 10,
      "num_kv_heads": 10,
      "vocab_size": 129280,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-OCR",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-0.5B-Instruct",
      "total_params_b": 0.5,
      "active_params_b": 0.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 896,
      "num_layers": 24,
      "num_heads": 14,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 45.0,
        "mmlu_pro": null,
        "humaneval": 30.5,
        "gsm8k": 36.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-0.5B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "phi-4",
      "total_params_b": 13.1,
      "active_params_b": 13.1,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 10,
      "vocab_size": 100352,
      "max_context_length": 16384,
      "effective_context_length": 16384,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 84.8,
        "mmlu_pro": 70.0,
        "humaneval": 82.6,
        "gsm8k": 95.0,
        "math": 80.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/phi-4",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-3B",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 63.4,
        "mmlu_pro": 37.3,
        "humaneval": 61.6,
        "gsm8k": 77.7,
        "math": 48.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-3B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2-2b-it",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2304,
      "num_layers": 26,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 52.0,
        "mmlu_pro": null,
        "humaneval": 26.8,
        "gsm8k": 58.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2-2b-it-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-Distill-Llama-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 70.0,
        "mmlu_pro": null,
        "humaneval": 65.0,
        "gsm8k": 88.0,
        "math": 72.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-11B-Vision-Instruct",
      "total_params_b": 11.0,
      "active_params_b": 11.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-11B-Vision-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-4B-Instruct",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-4B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Devstral-Small-2507",
      "total_params_b": 13.25,
      "active_params_b": 13.25,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Devstral-Small-2507-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 70.0,
        "mmlu_pro": null,
        "humaneval": 65.0,
        "gsm8k": 88.0,
        "math": 72.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-1.5B-Instruct",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 60.0,
        "mmlu_pro": null,
        "humaneval": 48.8,
        "gsm8k": 62.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-1.5B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-VL-3B-Instruct",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-VL-3B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-K2-Instruct",
      "total_params_b": 38.78,
      "active_params_b": 38.78,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 163840,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-K2-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-4-Scout-17B-16E-Instruct",
      "total_params_b": 17.0,
      "active_params_b": 1.06,
      "is_moe": true,
      "num_experts": 16,
      "num_active_experts": 1,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 10485760,
      "effective_context_length": 10485760,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-8B-Instruct-2512-FP8",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 34,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-8B-Instruct-2512-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-2B-Instruct",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-2B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-3B-Instruct-2512",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 26,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 19.1,
        "humaneval": 42.1,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-3B-Instruct-2512",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Nemotron-3-Nano-30B-A3B-FP8",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2688,
      "num_layers": 52,
      "num_heads": 32,
      "num_kv_heads": 2,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Nemotron-3-Nano-30B-A3B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "medgemma-4b-it",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 34,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/medgemma-4b-it-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-1B",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 49.3,
        "mmlu_pro": 24.7,
        "humaneval": 43.3,
        "gsm8k": 44.4,
        "math": 30.6,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-1B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Meta-Llama-3.1-70B-Instruct",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 66.4,
        "humaneval": 80.5,
        "gsm8k": 95.1,
        "math": 68.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Meta-Llama-3.1-70B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-235B-A22B-Thinking",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3n-E4B-it",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 35,
      "num_heads": 8,
      "num_kv_heads": 2,
      "vocab_size": 262400,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "functiongemma-270m-it",
      "total_params_b": 0.26,
      "active_params_b": 0.26,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 640,
      "num_layers": 18,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 44.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/functiongemma-270m-it",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.3-70B-Instruct",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 68.9,
        "humaneval": 88.4,
        "gsm8k": 95.1,
        "math": 77.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.3-70B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2-9b",
      "total_params_b": 9.0,
      "active_params_b": 9.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 42,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 71.0,
        "mmlu_pro": null,
        "humaneval": 40.2,
        "gsm8k": 76.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2-9b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-12b-it-qat",
      "total_params_b": 12.0,
      "active_params_b": 12.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3840,
      "num_layers": 48,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 4.1,
        "humaneval": 25.0,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "mistral-7b-instruct-v0.2",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32000,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.5,
        "mmlu_pro": null,
        "humaneval": 38.4,
        "gsm8k": 52.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/mistral-7b-instruct-v0.2-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-32B-Instruct",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 83.0,
        "mmlu_pro": 60.0,
        "humaneval": 82.0,
        "gsm8k": 92.0,
        "math": 67.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-32B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-235B-A22B",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-235B-A22B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-4B-Thinking-2507",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-4B-Thinking-2507-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "csm-1b",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 2051,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/csm-1b",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-VL-7B-Instruct",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-VL-7B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "mistral-7b",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32000,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.5,
        "mmlu_pro": null,
        "humaneval": 38.4,
        "gsm8k": 52.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/mistral-7b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 74.0,
        "mmlu_pro": 50.0,
        "humaneval": 75.0,
        "gsm8k": 85.0,
        "math": 55.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-7B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-235B-A22B-Instruct",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2-9b-it",
      "total_params_b": 9.0,
      "active_params_b": 9.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 42,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 71.0,
        "mmlu_pro": null,
        "humaneval": 40.2,
        "gsm8k": 76.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2-9b-it-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-30B-A3B-Instruct",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-30B-A3B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-30B-A3B-Instruct-2507",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-30B-A3B-Instruct-2507",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-Distill-Llama-70B",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-7B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-32B-Instruct",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-32B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Nemo-Instruct-2407",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 68.0,
        "mmlu_pro": null,
        "humaneval": 45.0,
        "gsm8k": 70.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-1.5B",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 60.0,
        "mmlu_pro": null,
        "humaneval": 48.8,
        "gsm8k": 62.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-1.5B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-1.5B-Instruct",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-1.5B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Phi-3.5-mini-instruct",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 32064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 69.0,
        "mmlu_pro": null,
        "humaneval": 62.8,
        "gsm8k": 86.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Phi-3.5-mini-instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-4-Maverick-17B-128E-Instruct",
      "total_params_b": 17.0,
      "active_params_b": 0.13,
      "is_moe": true,
      "num_experts": 128,
      "num_active_experts": 1,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 1048576,
      "effective_context_length": 1048576,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "embeddinggemma-300m",
      "total_params_b": 0.37,
      "active_params_b": 0.37,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 768,
      "num_layers": 24,
      "num_heads": 3,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/embeddinggemma-300m",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Small-Instruct-2409",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 6144,
      "num_layers": 56,
      "num_heads": 48,
      "num_kv_heads": 8,
      "vocab_size": 32768,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 19.1,
        "humaneval": 42.1,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Small-Instruct-2409-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 72.0,
        "mmlu_pro": null,
        "humaneval": 68.0,
        "gsm8k": 90.0,
        "math": 75.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-Distill-Qwen-7B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2b-it",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 18,
      "num_heads": 8,
      "num_kv_heads": 1,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 3.9,
        "humaneval": 17.7,
        "gsm8k": null,
        "math": 2.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2b-it",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-30B-A3B-128K",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-30B-A3B-128K-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Devstral-Small-2505",
      "total_params_b": 13.25,
      "active_params_b": 13.25,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Devstral-Small-2505-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-32B-Instruct",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 78.0,
        "mmlu_pro": null,
        "humaneval": 92.7,
        "gsm8k": 90.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-32B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-27b-it-qat",
      "total_params_b": 27.0,
      "active_params_b": 27.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5376,
      "num_layers": 62,
      "num_heads": 32,
      "num_kv_heads": 16,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-27b-it-qat-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Phi-4-mini-instruct",
      "total_params_b": 4.24,
      "active_params_b": 4.24,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 32,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 200064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 84.8,
        "mmlu_pro": 70.0,
        "humaneval": 82.6,
        "gsm8k": 95.0,
        "math": 80.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Phi-4-mini-instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Phi-4-mini-reasoning",
      "total_params_b": 4.24,
      "active_params_b": 4.24,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 32,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 200064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 84.8,
        "mmlu_pro": 70.0,
        "humaneval": 82.6,
        "gsm8k": 95.0,
        "math": 80.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Phi-4-mini-reasoning-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-14B-Instruct-2512-FP8",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-14B-Instruct-2512-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-0528",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 70.0,
        "mmlu_pro": null,
        "humaneval": 65.0,
        "gsm8k": 88.0,
        "math": 72.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-0528-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-14B-128K",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-14B-128K-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3n-E4B",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 35,
      "num_heads": 8,
      "num_kv_heads": 2,
      "vocab_size": 262400,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3n-E4B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Math-1.5B",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Math-1.5B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "tinyllama-chat",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 22,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 32000,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/tinyllama-chat-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 68.0,
        "mmlu_pro": null,
        "humaneval": 88.4,
        "gsm8k": 80.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-7B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "llama-2-7b-chat",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 32000,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 77.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/llama-2-7b-chat",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "MiMo-VL-7B-RL",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151680,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/MiMo-VL-7B-RL-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-0.5B",
      "total_params_b": 0.5,
      "active_params_b": 0.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 896,
      "num_layers": 24,
      "num_heads": 14,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 45.0,
        "mmlu_pro": null,
        "humaneval": 30.5,
        "gsm8k": 36.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-0.5B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-4b-pt",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 34,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-4b-pt-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-VL-2B-Instruct",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-VL-2B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-14B-Instruct",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 72.0,
        "mmlu_pro": null,
        "humaneval": 89.6,
        "gsm8k": 85.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Cosmos-Reason1-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Cosmos-Reason1-7B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-8B-Instruct-2512",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 34,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 19.1,
        "humaneval": 42.1,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-8B-Instruct-2512",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-32B",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 82.0,
        "mmlu_pro": null,
        "humaneval": 80.0,
        "gsm8k": 95.0,
        "math": 85.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-Distill-Qwen-32B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "tinyllama",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 22,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 32000,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/tinyllama-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Small-3.2-24B-Instruct-2506",
      "total_params_b": 24.0,
      "active_params_b": 24.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Small-3.2-24B-Instruct-2506-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "QwQ-32B",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/QwQ-32B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "medgemma-27b-text-it",
      "total_params_b": 27.0,
      "active_params_b": 27.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5376,
      "num_layers": 62,
      "num_heads": 32,
      "num_kv_heads": 16,
      "vocab_size": 262144,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/medgemma-27b-text-it-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-14B",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 78.0,
        "mmlu_pro": null,
        "humaneval": 75.0,
        "gsm8k": 93.0,
        "math": 80.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-Distill-Qwen-14B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-14B-Base",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-14B-Base-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3n-E2B-it",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 30,
      "num_heads": 8,
      "num_kv_heads": 2,
      "vocab_size": 262400,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 4.1,
        "humaneval": 25.0,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3n-E2B-it-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-14B-Instruct-2512",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 19.1,
        "humaneval": 42.1,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-14B-Instruct-2512",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2-2b",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2304,
      "num_layers": 26,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 52.0,
        "mmlu_pro": null,
        "humaneval": 26.8,
        "gsm8k": 58.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2-2b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Phi-4-reasoning-plus",
      "total_params_b": 13.1,
      "active_params_b": 13.1,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 10,
      "vocab_size": 100352,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 84.8,
        "mmlu_pro": 70.0,
        "humaneval": 82.6,
        "gsm8k": 95.0,
        "math": 80.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Phi-4-reasoning-plus-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-3B-Instruct",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-3B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-4b-it-qat",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 34,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "llama-2-7b",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 32000,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 77.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/llama-2-7b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3-0324",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 91.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3-0324-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-0.6B-Base",
      "total_params_b": 0.6,
      "active_params_b": 0.6,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-0.6B-Base-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-270m",
      "total_params_b": 0.26,
      "active_params_b": 0.26,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 640,
      "num_layers": 18,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-270m",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-8B-FP8",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-8B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-8B-Base",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 33.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-8B-Base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4-32B-0414",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 6144,
      "num_layers": 61,
      "num_heads": 48,
      "num_kv_heads": 2,
      "vocab_size": 151552,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4-32B-0414-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "orpheus-3b-0.1-pretrained",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 156939,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/orpheus-3b-0.1-pretrained",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2b",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 18,
      "num_heads": 8,
      "num_kv_heads": 1,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 4.1,
        "humaneval": 25.0,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-1.7B-Base",
      "total_params_b": 1.7,
      "active_params_b": 1.7,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-1.7B-Base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-72B-Instruct",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 65.0,
        "humaneval": 86.0,
        "gsm8k": 95.0,
        "math": 72.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-72B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Small-3.1-24B-Base-2503",
      "total_params_b": 24.0,
      "active_params_b": 24.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Small-3.1-24B-Base-2503-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-VL-72B-Instruct",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-VL-72B-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-32B-128K",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-32B-128K-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-3B",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 66.0,
        "mmlu_pro": null,
        "humaneval": 56.7,
        "gsm8k": 75.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-3B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Nemo-Base-2407",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-4B-128K",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-4B-128K-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4-9B-0414",
      "total_params_b": 9.0,
      "active_params_b": 9.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 2,
      "vocab_size": 151552,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4-9B-0414-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-0.5B-Instruct",
      "total_params_b": 0.5,
      "active_params_b": 0.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 896,
      "num_layers": 24,
      "num_heads": 14,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-0.5B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-0.5B-Instruct",
      "total_params_b": 0.5,
      "active_params_b": 0.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 896,
      "num_layers": 24,
      "num_heads": 14,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-0.5B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-30B-A3B-Thinking-2507",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-30B-A3B-Thinking-2507",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-8B-128K",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-8B-128K-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "LFM2-700M",
      "total_params_b": 0.55,
      "active_params_b": 0.55,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 16,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 65536,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/LFM2-700M",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-3B-Reasoning-2512",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 26,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-3B-Reasoning-2512-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-1.5B",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-1.5B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-1b",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 40,
      "num_heads": 12,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-1b",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.6V-Flash",
      "total_params_b": 8.67,
      "active_params_b": 8.67,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 2,
      "vocab_size": 151552,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.6V-Flash",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-7B-Instruct",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-7B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-OuteTTS-1.0-1B",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 134400,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-OuteTTS-1.0-1B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Math-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Math-7B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-8B-Thinking",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-8B-Thinking-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Meta-Llama-3.1-70B",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 66.4,
        "humaneval": 80.5,
        "gsm8k": 95.1,
        "math": 68.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Meta-Llama-3.1-70B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-Prover-V2-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 30,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 102400,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-Prover-V2-7B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-90B-Vision",
      "total_params_b": 90.0,
      "active_params_b": 90.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 100,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 77.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-90B-Vision-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-1b-pt",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1152,
      "num_layers": 26,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-1b-pt",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-1.5B",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-1.5B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-micro",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-micro-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-VL-32B-Instruct",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-VL-32B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Math-1.5B-Instruct",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Math-1.5B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-Z1-9B-0414",
      "total_params_b": 9.0,
      "active_params_b": 9.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 2,
      "vocab_size": 151552,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-Z1-9B-0414-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Seed-Coder-8B-Reasoning",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 155136,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 51.2,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Seed-Coder-8B-Reasoning-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-micro",
      "total_params_b": 2.22,
      "active_params_b": 2.22,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-micro",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-4-Maverick-17B-128E-Instruct-UD",
      "total_params_b": 17.0,
      "active_params_b": 0.13,
      "is_moe": true,
      "num_experts": 128,
      "num_active_experts": 1,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 1048576,
      "effective_context_length": 1048576,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF-UD",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM3-3B",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 4,
      "vocab_size": 128256,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 61.6,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM3-3B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2-27b-it",
      "total_params_b": 27.0,
      "active_params_b": 27.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4608,
      "num_layers": 46,
      "num_heads": 32,
      "num_kv_heads": 16,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 75.0,
        "mmlu_pro": null,
        "humaneval": 51.8,
        "gsm8k": 83.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2-27b-it-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Seed-Coder-8B-Instruct",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 155136,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 81.7,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Seed-Coder-8B-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-3B",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-3B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Math-7B-Instruct",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Math-7B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-14B-Reasoning-2512",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-14B-Reasoning-2512",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "codegemma-2b",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 18,
      "num_heads": 8,
      "num_kv_heads": 1,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 26.8,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/codegemma-2b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "LFM2-350M",
      "total_params_b": 0.27,
      "active_params_b": 0.27,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 16,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 65536,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/LFM2-350M",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Magistral-Small-2509-FP8-Dynamic",
      "total_params_b": 13.25,
      "active_params_b": 13.25,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Magistral-Small-2509-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "llama-3-70b",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 77.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/llama-3-70b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "ERNIE-4.5-VL-28B-A3B-PT",
      "total_params_b": 28.0,
      "active_params_b": 28.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 28,
      "num_heads": 20,
      "num_kv_heads": 4,
      "vocab_size": 103424,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/ERNIE-4.5-VL-28B-A3B-PT",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3-0324-UD",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 91.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3-0324-GGUF-UD",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Phi-4-reasoning",
      "total_params_b": 13.1,
      "active_params_b": 13.1,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 10,
      "vocab_size": 100352,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 84.8,
        "mmlu_pro": 70.0,
        "humaneval": 82.6,
        "gsm8k": 95.0,
        "math": 80.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Phi-4-reasoning-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Magistral-Small-2509",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Magistral-Small-2509-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Phi-3-medium-4k-instruct",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 10,
      "vocab_size": 32064,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 78.0,
        "mmlu_pro": null,
        "humaneval": 62.2,
        "gsm8k": 91.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Phi-3-medium-4k-instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-235B-A22B-128K",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-235B-A22B-128K-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "OLMo-2-0425-1B-Instruct",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 16,
      "num_kv_heads": 16,
      "vocab_size": 100352,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/OLMo-2-0425-1B-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-0528-BF16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-0528-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-350m",
      "total_params_b": 0.46,
      "active_params_b": 0.46,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-350m",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3n-E2B",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 30,
      "num_heads": 8,
      "num_kv_heads": 2,
      "vocab_size": 262400,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 4.1,
        "humaneval": 25.0,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3n-E2B-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-0.5B",
      "total_params_b": 0.5,
      "active_params_b": 0.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 896,
      "num_layers": 24,
      "num_heads": 14,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-0.5B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-14B",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 79.0,
        "mmlu_pro": 55.0,
        "humaneval": 80.0,
        "gsm8k": 90.0,
        "math": 62.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-14B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "codellama-7b",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 32016,
      "max_context_length": 16384,
      "effective_context_length": 16384,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 37.8,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/codellama-7b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-7b-it",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 16,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-7b-it-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "LFM2-1.2B",
      "total_params_b": 1.2,
      "active_params_b": 1.2,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 65536,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/LFM2-1.2B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-14B-FP8",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-14B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3_1-Nemotron-Ultra-253B-v1",
      "total_params_b": 253.0,
      "active_params_b": 253.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 16384,
      "num_layers": 162,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3_1-Nemotron-Ultra-253B-v1-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Hermes-3-Llama-3.1-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Hermes-3-Llama-3.1-8B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-tiny",
      "total_params_b": 65.87,
      "active_params_b": 6.18,
      "is_moe": true,
      "num_experts": 64,
      "num_active_experts": 6,
      "hidden_dim": 1536,
      "num_layers": 40,
      "num_heads": 12,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-tiny",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Magistral-Small-2507",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 28.7,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Magistral-Small-2507-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-32B-Thinking",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-32B-Thinking-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-3B-Base-2512",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 26,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-3B-Base-2512",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-11B-Vision",
      "total_params_b": 11.0,
      "active_params_b": 11.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-11B-Vision-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-12b-pt",
      "total_params_b": 12.0,
      "active_params_b": 12.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3840,
      "num_layers": 48,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 4.1,
        "humaneval": 25.0,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-12b-pt-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-3.3-2b-instruct",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 49159,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-3.3-2b-instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM2-135M",
      "total_params_b": 0.15,
      "active_params_b": 0.15,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 576,
      "num_layers": 30,
      "num_heads": 9,
      "num_kv_heads": 3,
      "vocab_size": 49153,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM2-135M",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2-it",
      "total_params_b": 2.25,
      "active_params_b": 2.25,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2304,
      "num_layers": 26,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 4.1,
        "humaneval": 25.0,
        "gsm8k": null,
        "math": 3.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2-it-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-4b-it-FP8-Dynamic",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 34,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-4b-it-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-7b",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 16,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-7b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-4B-Instruct-2507-FP8",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-4B-Instruct-2507-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "KernelLLM",
      "total_params_b": 6.97,
      "active_params_b": 6.97,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/KernelLLM-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Hermes-4-405B",
      "total_params_b": 405.0,
      "active_params_b": 405.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 16384,
      "num_layers": 126,
      "num_heads": 128,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Hermes-4-405B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-1B-Instruct-FP8-Block",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 49.3,
        "mmlu_pro": 24.7,
        "humaneval": 43.3,
        "gsm8k": 44.4,
        "math": 30.6,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-1B-Instruct-FP8-Block",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-K2-Thinking-BF16",
      "total_params_b": 38.78,
      "active_params_b": 38.78,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 163840,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-K2-Thinking-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-30B-A3B-Instruct-2507-FP8",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-Nemotron-Nano-4B-v1.1-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-16B-A3B",
      "total_params_b": 16.0,
      "active_params_b": 16.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-16B-A3B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-Nemotron-Nano-8B-v1",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-Nemotron-Nano-8B-v1-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "r1-1776-distill-llama-70b",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/r1-1776-distill-llama-70b-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM2-135M-Instruct",
      "total_params_b": 0.15,
      "active_params_b": 0.15,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 576,
      "num_layers": 30,
      "num_heads": 9,
      "num_kv_heads": 3,
      "vocab_size": 49153,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM2-135M-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-4-Scout-17B-16E",
      "total_params_b": 17.0,
      "active_params_b": 1.06,
      "is_moe": true,
      "num_experts": 16,
      "num_active_experts": 1,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-4-Scout-17B-16E",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-8B-Reasoning-2512",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 34,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-8B-Reasoning-2512",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-350m",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 768,
      "num_layers": 32,
      "num_heads": 12,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-350m-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-14B-Base-2512",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-14B-Base-2512-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-Prover-V2-671B",
      "total_params_b": 671.0,
      "active_params_b": 671.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 74.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-Prover-V2-671B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-2B-Thinking",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-2B-Thinking-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3_3-Nemotron-Super-49B-v1",
      "total_params_b": 49.0,
      "active_params_b": 49.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3_3-Nemotron-Super-49B-v1-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Devstral-2-123B-Instruct-2512",
      "total_params_b": 123.0,
      "active_params_b": 123.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 12288,
      "num_layers": 88,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 24.0,
        "humaneval": 79.9,
        "gsm8k": null,
        "math": 10.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Devstral-2-123B-Instruct-2512",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "mistral-7b-instruct-v0.1",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32000,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.5,
        "mmlu_pro": null,
        "humaneval": 38.4,
        "gsm8k": 52.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/mistral-7b-instruct-v0.1-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "llama-3-70b-Instruct",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 77.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/llama-3-70b-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-0.5B",
      "total_params_b": 0.5,
      "active_params_b": 0.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 896,
      "num_layers": 24,
      "num_heads": 14,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-0.5B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-270m-it-qat",
      "total_params_b": 0.26,
      "active_params_b": 0.26,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 640,
      "num_layers": 18,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-270m-it-qat",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-4B-FP8",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-4B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-K2-Instruct-BF16",
      "total_params_b": 38.78,
      "active_params_b": 38.78,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 163840,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-K2-Instruct-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-small",
      "total_params_b": 4.0,
      "active_params_b": 0.56,
      "is_moe": true,
      "num_experts": 72,
      "num_active_experts": 10,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-small-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-4b-it-qat-int4",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 34,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-4b-it-qat-int4-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Nanonets-OCR-s",
      "total_params_b": 2.12,
      "active_params_b": 2.12,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Nanonets-OCR-s",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "codegemma-7b-it",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 16,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 44.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/codegemma-7b-it-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-2-27b",
      "total_params_b": 27.0,
      "active_params_b": 27.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4608,
      "num_layers": 46,
      "num_heads": 32,
      "num_kv_heads": 16,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 75.0,
        "mmlu_pro": null,
        "humaneval": 51.8,
        "gsm8k": 83.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-2-27b",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-14B",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 72.0,
        "mmlu_pro": null,
        "humaneval": 89.6,
        "gsm8k": 85.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-14B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Falcon-H1-0.5B-Instruct",
      "total_params_b": 0.5,
      "active_params_b": 0.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 36,
      "num_heads": 8,
      "num_kv_heads": 2,
      "vocab_size": 32784,
      "max_context_length": 16384,
      "effective_context_length": 16384,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Falcon-H1-0.5B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "zephyr-sft",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32000,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 30.0,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/zephyr-sft-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM2-360M-Instruct",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 960,
      "num_layers": 32,
      "num_heads": 15,
      "num_kv_heads": 5,
      "vocab_size": 49153,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM2-360M-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "phi-2",
      "total_params_b": 2.65,
      "active_params_b": 2.65,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 51200,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 49.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/phi-2",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "OpenHermes-2.5-Mistral-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32002,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.5,
        "mmlu_pro": null,
        "humaneval": 38.4,
        "gsm8k": 52.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/OpenHermes-2.5-Mistral-7B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-Next-80B-A3B-Thinking",
      "total_params_b": 80.0,
      "active_params_b": 80.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-Next-80B-A3B-Thinking",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-32B",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 83.0,
        "mmlu_pro": 60.0,
        "humaneval": 82.0,
        "gsm8k": 92.0,
        "math": 67.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-32B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM2-1.7B-Instruct",
      "total_params_b": 1.7,
      "active_params_b": 1.7,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 24,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 49153,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 2.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM2-1.7B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "LFM2-2.6B-Exp",
      "total_params_b": 2.6,
      "active_params_b": 2.6,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 30,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 65536,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/LFM2-2.6B-Exp",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "llama-2-13b",
      "total_params_b": 13.0,
      "active_params_b": 13.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 40,
      "vocab_size": 32000,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 42.7,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/llama-2-13b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "AceReason-Nemotron-14B",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/AceReason-Nemotron-14B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM-135M",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 576,
      "num_layers": 30,
      "num_heads": 9,
      "num_kv_heads": 3,
      "vocab_size": 49152,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM-135M-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-Storm-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 69.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-Storm-8B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-8B-Base-2512",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 34,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-8B-Base-2512",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-1b-it-qat",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1152,
      "num_layers": 26,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-1b-it-qat",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-UD",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-GGUF-UD",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-30B-A3B-Base",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-30B-A3B-Base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "PaddleOCR-VL",
      "total_params_b": 0.33,
      "active_params_b": 0.33,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 18,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 103424,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/PaddleOCR-VL",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Large-Instruct-2407",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 12288,
      "num_layers": 88,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 32768,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 69.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Large-Instruct-2407-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-micro-base",
      "total_params_b": 3.4,
      "active_params_b": 3.4,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-micro-base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-8B-Instruct-FP8",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-8B-Instruct-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-27b-pt",
      "total_params_b": 27.0,
      "active_params_b": 27.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5376,
      "num_layers": 62,
      "num_heads": 32,
      "num_kv_heads": 16,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-27b-pt",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Ministral-3-3B-Instruct-2512-FP8",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 26,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Ministral-3-3B-Instruct-2512-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-14B-Instruct-1M",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 1010000,
      "effective_context_length": 1010000,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 79.0,
        "mmlu_pro": 55.0,
        "humaneval": 80.0,
        "gsm8k": 90.0,
        "math": 62.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-14B-Instruct-1M-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM-135M-Instruct",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 576,
      "num_layers": 30,
      "num_heads": 9,
      "num_kv_heads": 3,
      "vocab_size": 49152,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM-135M-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Hermes-4-70B",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Hermes-4-70B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "MAI-DS-R1",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/MAI-DS-R1-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llasa-1B",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 193800,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 61.6,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llasa-1B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3-bf16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 81.1,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3-bf16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "mistral-7b-v0.2",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32000,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.5,
        "mmlu_pro": null,
        "humaneval": 38.4,
        "gsm8k": 52.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/mistral-7b-v0.2-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-1b",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 40,
      "num_heads": 16,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-1b",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-90B-Vision-Instruct",
      "total_params_b": 90.0,
      "active_params_b": 90.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 100,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 77.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mixtral-8x7B-Instruct-v0.1",
      "total_params_b": 7.0,
      "active_params_b": 1.75,
      "is_moe": true,
      "num_experts": 8,
      "num_active_experts": 2,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32000,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 70.6,
        "mmlu_pro": null,
        "humaneval": 40.2,
        "gsm8k": 60.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mixtral-8x7B-Instruct-v0.1-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Olmo-3-7B-Instruct",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 100278,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 77.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Olmo-3-7B-Instruct-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Olmo-3-7B-Think",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 100278,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Olmo-3-7B-Think-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "r1-1776",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 70.0,
        "mmlu_pro": null,
        "humaneval": 65.0,
        "gsm8k": 88.0,
        "math": 72.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/r1-1776-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-0.6B-FP8",
      "total_params_b": 0.6,
      "active_params_b": 0.6,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-0.6B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Nemotron-3-Nano-30B-A3B-Base",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2688,
      "num_layers": 52,
      "num_heads": 32,
      "num_kv_heads": 2,
      "vocab_size": 131072,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Nemotron-3-Nano-30B-A3B-Base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-32B-FP8",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-32B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-1b-it-FP8-Dynamic",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1152,
      "num_layers": 26,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-1b-it-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Magistral-Small-2506",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Magistral-Small-2506-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-27b-it-FP8-Dynamic",
      "total_params_b": 27.0,
      "active_params_b": 27.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5376,
      "num_layers": 62,
      "num_heads": 32,
      "num_kv_heads": 16,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-27b-it-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "INTELLECT-2",
      "total_params_b": 20.91,
      "active_params_b": 20.91,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/INTELLECT-2-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "c4ai-command-a-03-2025",
      "total_params_b": 119.11,
      "active_params_b": 119.11,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 12288,
      "num_layers": 64,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 256000,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/c4ai-command-a-03-2025-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Coder-32B",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 78.0,
        "mmlu_pro": null,
        "humaneval": 92.7,
        "gsm8k": 90.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Coder-32B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gpt-oss-safeguard-20b-BF16",
      "total_params_b": 20.0,
      "active_params_b": 2.5,
      "is_moe": true,
      "num_experts": 32,
      "num_active_experts": 4,
      "hidden_dim": 2880,
      "num_layers": 24,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 201088,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gpt-oss-safeguard-20b-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-3.3-8b-instruct",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 49159,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-3.3-8b-instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-1.7B-FP8",
      "total_params_b": 1.7,
      "active_params_b": 1.7,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-1.7B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-4B-Instruct-FP8",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-4B-Instruct-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-1B-Instruct-FP8-Dynamic",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 49.3,
        "mmlu_pro": 24.7,
        "humaneval": 43.3,
        "gsm8k": 44.4,
        "math": 30.6,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-1B-Instruct-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-1.1-2b-it",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 18,
      "num_heads": 8,
      "num_kv_heads": 1,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 5.4,
        "humaneval": 22.6,
        "gsm8k": null,
        "math": 1.8,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-1.1-2b-it-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "NVIDIA-Nemotron-Nano-9B-v2",
      "total_params_b": 9.0,
      "active_params_b": 9.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4480,
      "num_layers": 56,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/NVIDIA-Nemotron-Nano-9B-v2",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Falcon-H1-7B-Instruct",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 44,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 130049,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Falcon-H1-7B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "QwQ-32B-Preview",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 52.0,
        "humaneval": null,
        "gsm8k": null,
        "math": 44.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/QwQ-32B-Preview-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "phi-4-reasoning",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 10,
      "vocab_size": 100352,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 84.8,
        "mmlu_pro": 70.0,
        "humaneval": 82.6,
        "gsm8k": 95.0,
        "math": 80.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/phi-4-reasoning-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-small-FP8-Dynamic",
      "total_params_b": 487.53,
      "active_params_b": 67.71,
      "is_moe": true,
      "num_experts": 72,
      "num_active_experts": 10,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-small-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Seed-OSS-36B-Instruct",
      "total_params_b": 36.0,
      "active_params_b": 36.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 80,
      "num_kv_heads": 8,
      "vocab_size": 155136,
      "max_context_length": 524288,
      "effective_context_length": 524288,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Seed-OSS-36B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "codegemma-7b",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 16,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 44.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/codegemma-7b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM3-3B-Base",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 4,
      "vocab_size": 128256,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 33.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM3-3B-Base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-VL-72B-Instruct",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-VL-72B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-270m-it-FP8-Dynamic",
      "total_params_b": 0.26,
      "active_params_b": 0.26,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 640,
      "num_layers": 18,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-270m-it-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "OLMo-2-0325-32B-Instruct",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/OLMo-2-0325-32B-Instruct-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mixtral-8x7B-v0.1",
      "total_params_b": 7.0,
      "active_params_b": 1.75,
      "is_moe": true,
      "num_experts": 8,
      "num_active_experts": 2,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32000,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 70.6,
        "mmlu_pro": null,
        "humaneval": 40.2,
        "gsm8k": 60.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mixtral-8x7B-v0.1-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Jan-nano-128k",
      "total_params_b": 3.22,
      "active_params_b": 3.22,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Jan-nano-128k",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-1b-base",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 40,
      "num_heads": 16,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-1b-base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-tiny-FP8-Dynamic",
      "total_params_b": 65.87,
      "active_params_b": 6.18,
      "is_moe": true,
      "num_experts": 64,
      "num_active_experts": 6,
      "hidden_dim": 1536,
      "num_layers": 40,
      "num_heads": 12,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-tiny-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Mistral-Small-24B-Base-2501",
      "total_params_b": 24.0,
      "active_params_b": 24.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Mistral-Small-24B-Base-2501-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-32B-Instruct-FP8",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-32B-Instruct-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gpt-oss-safeguard-20b",
      "total_params_b": 20.0,
      "active_params_b": 2.5,
      "is_moe": true,
      "num_experts": 32,
      "num_active_experts": 4,
      "hidden_dim": 2880,
      "num_layers": 24,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 201088,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gpt-oss-safeguard-20b",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-tiny-base",
      "total_params_b": 65.87,
      "active_params_b": 6.18,
      "is_moe": true,
      "num_experts": 64,
      "num_active_experts": 6,
      "hidden_dim": 1536,
      "num_layers": 40,
      "num_heads": 12,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-tiny-base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Yi-1.5-6B",
      "total_params_b": 6.0,
      "active_params_b": 6.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 64000,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.0,
        "mmlu_pro": null,
        "humaneval": 41.5,
        "gsm8k": 70.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Yi-1.5-6B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3_3-Nemotron-Super-49B-v1_5",
      "total_params_b": 49.0,
      "active_params_b": 49.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3_3-Nemotron-Super-49B-v1_5",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "ERNIE-4.5-21B-A3B-PT",
      "total_params_b": 21.0,
      "active_params_b": 21.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 28,
      "num_heads": 20,
      "num_kv_heads": 4,
      "vocab_size": 103424,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/ERNIE-4.5-21B-A3B-PT",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Olmo-3.1-32B-Instruct",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 100278,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 69.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Olmo-3.1-32B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-12b-it-FP8-Dynamic",
      "total_params_b": 12.0,
      "active_params_b": 12.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3840,
      "num_layers": 48,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-12b-it-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "codellama-34b",
      "total_params_b": 34.0,
      "active_params_b": 34.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 48,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 32000,
      "max_context_length": 16384,
      "effective_context_length": 16384,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 51.8,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/codellama-34b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-72B-Instruct",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-72B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-72B",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-72B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-235B-A22B-Thinking-2507",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-235B-A22B-Thinking-2507",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-4-Maverick-17B-128E",
      "total_params_b": 17.0,
      "active_params_b": 0.13,
      "is_moe": true,
      "num_experts": 128,
      "num_active_experts": 1,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-4-Maverick-17B-128E",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-Z1-32B-0414",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 6144,
      "num_layers": 61,
      "num_heads": 48,
      "num_kv_heads": 2,
      "vocab_size": 151552,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-Z1-32B-0414-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Apriel-1.5-15b-Thinker",
      "total_params_b": 15.0,
      "active_params_b": 15.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 262400,
      "effective_context_length": 262400,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Apriel-1.5-15b-Thinker",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM-1.7B-Instruct",
      "total_params_b": 1.7,
      "active_params_b": 1.7,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 24,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 49152,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 2.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM-1.7B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-30B-A3B-Thinking",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-30B-A3B-Thinking",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-Nemotron-70B-Instruct",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 77.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-Nemotron-70B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM2-360M",
      "total_params_b": 0.4,
      "active_params_b": 0.4,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 960,
      "num_layers": 32,
      "num_heads": 15,
      "num_kv_heads": 5,
      "vocab_size": 49153,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM2-360M",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-3.2-2b-instruct",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 49155,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-3.2-2b-instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-8B-Thinking-FP8",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-8B-Thinking-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-8B-Instruct-FP8-Dynamic",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-8B-Instruct-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-1.1-7b-it",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 16,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 17.6,
        "humaneval": 42.7,
        "gsm8k": null,
        "math": 4.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-1.1-7b-it-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "MiniMax-M2.1",
      "total_params_b": 1563.82,
      "active_params_b": 48.87,
      "is_moe": true,
      "num_experts": 256,
      "num_active_experts": 8,
      "hidden_dim": 3072,
      "num_layers": 62,
      "num_heads": 48,
      "num_kv_heads": 8,
      "vocab_size": 200064,
      "max_context_length": 196608,
      "effective_context_length": 196608,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/MiniMax-M2.1",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-72B",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 65.0,
        "humaneval": 86.0,
        "gsm8k": 95.0,
        "math": 72.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-72B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "medgemma-4b-pt",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 34,
      "num_heads": 8,
      "num_kv_heads": 4,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/medgemma-4b-pt",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "medgemma-27b-it",
      "total_params_b": 27.0,
      "active_params_b": 27.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5376,
      "num_layers": 62,
      "num_heads": 32,
      "num_kv_heads": 16,
      "vocab_size": 262208,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 21.6,
        "humaneval": 35.4,
        "gsm8k": null,
        "math": 7.4,
        "bfcl": null
      },
      "hf_model_id": "unsloth/medgemma-27b-it",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-small-base",
      "total_params_b": 487.53,
      "active_params_b": 67.71,
      "is_moe": true,
      "num_experts": 72,
      "num_active_experts": 10,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-small-base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-K2-Thinking",
      "total_params_b": 38.78,
      "active_params_b": 38.78,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 163840,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-K2-Thinking",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.7",
      "total_params_b": 29.72,
      "active_params_b": 29.72,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 92,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151552,
      "max_context_length": 202752,
      "effective_context_length": 202752,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.7",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM-360M-Instruct",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 960,
      "num_layers": 32,
      "num_heads": 15,
      "num_kv_heads": 5,
      "vocab_size": 49152,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM-360M-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-30B-A3B-Instruct-FP8",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "aya-vision-8b",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/aya-vision-8b",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.1-Base",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 51.2,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.1-Base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.1-Terminus-BF16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.1-Terminus-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "LFM2-8B-A1B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 24,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 65536,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/LFM2-8B-A1B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "EXAONE-4.0-32B",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 102400,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/EXAONE-4.0-32B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.2",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.2",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "yi-6b",
      "total_params_b": 6.0,
      "active_params_b": 6.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 64000,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/yi-6b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Meta-Llama-3.1-405B",
      "total_params_b": 405.0,
      "active_params_b": 405.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 16384,
      "num_layers": 126,
      "num_heads": 128,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 88.6,
        "mmlu_pro": 73.3,
        "humaneval": 89.0,
        "gsm8k": 96.8,
        "math": 73.8,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Meta-Llama-3.1-405B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM2-1.7B",
      "total_params_b": 1.7,
      "active_params_b": 1.7,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 24,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 49153,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 2.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM2-1.7B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-VL-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-VL-7B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.5-Air",
      "total_params_b": 9.88,
      "active_params_b": 9.88,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 46,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151552,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.5-Air",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "yi-34b-chat",
      "total_params_b": 34.0,
      "active_params_b": 34.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 60,
      "num_heads": 56,
      "num_kv_heads": 8,
      "vocab_size": 64000,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/yi-34b-chat-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "ERNIE-4.5-0.3B-PT",
      "total_params_b": 0.3,
      "active_params_b": 0.3,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 18,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 103424,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/ERNIE-4.5-0.3B-PT",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-3B-Instruct-FP8-Dynamic",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 63.4,
        "mmlu_pro": 37.3,
        "humaneval": 61.6,
        "gsm8k": 77.7,
        "math": 48.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-3B-Instruct-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-235B-A22B-Instruct-2507",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-235B-A22B-Instruct-2507",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llasa-3B",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 193800,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 61.6,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llasa-3B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-350m-base",
      "total_params_b": 0.3,
      "active_params_b": 0.3,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 768,
      "num_layers": 32,
      "num_heads": 12,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-350m-base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Math-72B-Instruct",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Math-72B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-Coder-480B-A35B-Instruct-1M",
      "total_params_b": 480.0,
      "active_params_b": 480.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 6144,
      "num_layers": 62,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 1048576,
      "effective_context_length": 1048576,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Meta-Llama-3.1-405B-Instruct",
      "total_params_b": 405.0,
      "active_params_b": 405.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 16384,
      "num_layers": 126,
      "num_heads": 128,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 88.6,
        "mmlu_pro": 73.3,
        "humaneval": 89.0,
        "gsm8k": 96.8,
        "math": 73.8,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Meta-Llama-3.1-405B-Instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-2B-Instruct-FP8",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-2B-Instruct-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-235B-A22B-Thinking-FP8",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-micro-base",
      "total_params_b": 2.22,
      "active_params_b": 2.22,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-micro-base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "c4ai-command-r-08-2024",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 40,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 256000,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/c4ai-command-r-08-2024-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "JanusCoder-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 81.7,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/JanusCoder-8B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "reka-flash-3",
      "total_params_b": 20.55,
      "active_params_b": 20.55,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 6144,
      "num_layers": 44,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 100352,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/reka-flash-3-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-vision-3.2-2b",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 49156,
      "max_context_length": 16384,
      "effective_context_length": 16384,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-vision-3.2-2b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "codellama-13b",
      "total_params_b": 13.0,
      "active_params_b": 13.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 40,
      "vocab_size": 32016,
      "max_context_length": 16384,
      "effective_context_length": 16384,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 42.7,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/codellama-13b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "total_params_b": 17.0,
      "active_params_b": 0.13,
      "is_moe": true,
      "num_experts": 128,
      "num_active_experts": 1,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 1048576,
      "effective_context_length": 1048576,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-K2-Base-BF16",
      "total_params_b": 38.78,
      "active_params_b": 38.78,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 163840,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-K2-Base-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.6V-FP8",
      "total_params_b": 9.88,
      "active_params_b": 9.88,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 46,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151552,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.6V-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Falcon-H1-3B-Instruct",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 32,
      "num_heads": 10,
      "num_kv_heads": 2,
      "vocab_size": 65537,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 56.1,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Falcon-H1-3B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM-360M",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 960,
      "num_layers": 32,
      "num_heads": 15,
      "num_kv_heads": 5,
      "vocab_size": 49152,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM-360M-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.6",
      "total_params_b": 29.72,
      "active_params_b": 29.72,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 92,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151552,
      "max_context_length": 202752,
      "effective_context_length": 202752,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.6",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.6V",
      "total_params_b": 9.88,
      "active_params_b": 9.88,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 46,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151552,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.6V",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-BF16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 81.1,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "ERNIE-4.5-21B-A3B-Thinking",
      "total_params_b": 21.0,
      "active_params_b": 21.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 28,
      "num_heads": 20,
      "num_kv_heads": 4,
      "vocab_size": 103424,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/ERNIE-4.5-21B-A3B-Thinking",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-30B-A3B-Thinking-2507-FP8",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Olmo-3.1-32B-Think",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 100278,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Olmo-3.1-32B-Think",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepScaleR-1.5B-Preview",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 24576,
      "effective_context_length": 24576,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepScaleR-1.5B-Preview",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-4B-Thinking-2507-FP8",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-4B-Thinking-2507-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-K2-Instruct-0905",
      "total_params_b": 38.78,
      "active_params_b": 38.78,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 163840,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-K2-Instruct-0905",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-30B-A3B-Thinking-FP8",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Falcon-H1-1.5B-Instruct",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 24,
      "num_heads": 8,
      "num_kv_heads": 2,
      "vocab_size": 65537,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Falcon-H1-1.5B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-K2-Instruct-0905-BF16",
      "total_params_b": 38.78,
      "active_params_b": 38.78,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 163840,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-K2-Instruct-0905-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM-1.7B",
      "total_params_b": 1.7,
      "active_params_b": 1.7,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 24,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 49152,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 2.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM-1.7B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Apertus-8B-Instruct-2509",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Apertus-8B-Instruct-2509-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "MiniMax-M2",
      "total_params_b": 1563.82,
      "active_params_b": 48.87,
      "is_moe": true,
      "num_experts": 256,
      "num_active_experts": 8,
      "hidden_dim": 3072,
      "num_layers": 62,
      "num_heads": 48,
      "num_kv_heads": 8,
      "vocab_size": 200064,
      "max_context_length": 196608,
      "effective_context_length": 196608,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/MiniMax-M2",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.1",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.1",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "embeddinggemma-300m-qat-q8_0-unquantized",
      "total_params_b": 0.37,
      "active_params_b": 0.37,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 768,
      "num_layers": 24,
      "num_heads": 3,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/embeddinggemma-300m-qat-q8_0-unquantized",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-3B-Instruct-FP8-Block",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 63.4,
        "mmlu_pro": 37.3,
        "humaneval": 61.6,
        "gsm8k": 77.7,
        "math": 48.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-3B-Instruct-FP8-Block",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.7-FP8",
      "total_params_b": 29.72,
      "active_params_b": 29.72,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 92,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151552,
      "max_context_length": 202752,
      "effective_context_length": 202752,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.7-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-h-1b-base",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 40,
      "num_heads": 12,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-h-1b-base-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.2-Speciale",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.2-Speciale",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-235B-A22B-Instruct-2507-FP8",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-Coder-480B-A35B-Instruct-FP8",
      "total_params_b": 480.0,
      "active_params_b": 480.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 6144,
      "num_layers": 62,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-K2-Base",
      "total_params_b": 38.78,
      "active_params_b": 38.78,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 64,
      "num_kv_heads": 64,
      "vocab_size": 163840,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-K2-Base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.1-Terminus",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.1-Terminus",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.3-70B-Instruct-FP8-Dynamic",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 68.9,
        "humaneval": 88.4,
        "gsm8k": 95.1,
        "math": 77.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.3-70B-Instruct-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Hermes-2-Pro-Mistral-7B",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32032,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 62.5,
        "mmlu_pro": null,
        "humaneval": 38.4,
        "gsm8k": 52.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Hermes-2-Pro-Mistral-7B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-Math-1.5B",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-Math-1.5B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-30B-A3B-FP8",
      "total_params_b": 30.0,
      "active_params_b": 30.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 48,
      "num_heads": 32,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-30B-A3B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "embeddinggemma-300m-qat-q4_0-unquantized",
      "total_params_b": 0.37,
      "active_params_b": 0.37,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 768,
      "num_layers": 24,
      "num_heads": 3,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 2048,
      "effective_context_length": 2048,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/embeddinggemma-300m-qat-q4_0-unquantized",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Phi-3-mini-4k-instruct-v0",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 32,
      "vocab_size": 32064,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 68.8,
        "mmlu_pro": null,
        "humaneval": 58.5,
        "gsm8k": 82.5,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Phi-3-mini-4k-instruct-v0-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-4-Scout-17B-16E-Instruct-dynamic",
      "total_params_b": 17.0,
      "active_params_b": 1.06,
      "is_moe": true,
      "num_experts": 16,
      "num_active_experts": 1,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 10485760,
      "effective_context_length": 10485760,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-unsloth-dynamic-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-Zero",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-Zero",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-Guard-4-12B",
      "total_params_b": 12.0,
      "active_params_b": 12.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 10485760,
      "effective_context_length": 10485760,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-Guard-4-12B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-TNG-R1T2-Chimera",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-TNG-R1T2-Chimera",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-235B-A22B-Thinking-2507-FP8",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-235B-A22B-Thinking-2507-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Reflection-Llama-3.1-70B",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128262,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 66.4,
        "humaneval": 80.5,
        "gsm8k": 95.1,
        "math": 68.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Reflection-Llama-3.1-70B-GGUF",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-Math-V2",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 85.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-Math-V2",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.5",
      "total_params_b": 29.72,
      "active_params_b": 29.72,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 92,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151552,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.5",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-32B-Thinking-FP8",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-32B-Thinking-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-VL-2B",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1536,
      "num_layers": 28,
      "num_heads": 12,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-VL-2B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-3.2-8b-instruct",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 49155,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-3.2-8b-instruct-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3n-E2B-it-litert-preview",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 30,
      "num_heads": 8,
      "num_kv_heads": 2,
      "vocab_size": 262400,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3n-E2B-it-litert-preview",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.1-Base-BF16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 51.2,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.1-Base-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.3-Nemotron-70B-Edit",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.3-Nemotron-70B-Edit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3n-E4B-it-litert-preview",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 35,
      "num_heads": 8,
      "num_kv_heads": 2,
      "vocab_size": 262400,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3n-E4B-it-litert-preview",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-Coder-480B-A35B-Instruct",
      "total_params_b": 480.0,
      "active_params_b": 480.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 6144,
      "num_layers": 62,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": 37.9,
        "humaneval": 92.1,
        "gsm8k": null,
        "math": 49.5,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Apertus-70B-Instruct-2509",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Apertus-70B-Instruct-2509-unsloth-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Hunyuan-A13B-Instruct",
      "total_params_b": 13.0,
      "active_params_b": 13.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128167,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 17.1,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Hunyuan-A13B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "SmolLM3-3B-128K",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 4,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/SmolLM3-3B-128K",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "grok-2",
      "total_params_b": 336.73,
      "active_params_b": 84.18,
      "is_moe": true,
      "num_experts": 8,
      "num_active_experts": 2,
      "hidden_dim": 8192,
      "num_layers": 64,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/grok-2",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-2B-Thinking-FP8",
      "total_params_b": 2.0,
      "active_params_b": 2.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-2B-Thinking-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-7B-Instruct-1M",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3584,
      "num_layers": 28,
      "num_heads": 28,
      "num_kv_heads": 4,
      "vocab_size": 152064,
      "max_context_length": 1010000,
      "effective_context_length": 1010000,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 74.0,
        "mmlu_pro": 50.0,
        "humaneval": 75.0,
        "gsm8k": 85.0,
        "math": 55.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-7B-Instruct-1M",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Magistral-Small-2509-FP8-torchao",
      "total_params_b": 13.25,
      "active_params_b": 13.25,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Magistral-Small-2509-FP8-torchao",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-4B-Thinking-FP8",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-4B-Thinking-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "granite-4.0-350m-base",
      "total_params_b": 0.46,
      "active_params_b": 0.46,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1024,
      "num_layers": 28,
      "num_heads": 16,
      "num_kv_heads": 4,
      "vocab_size": 100352,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/granite-4.0-350m-base",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "yi-34b",
      "total_params_b": 34.0,
      "active_params_b": 34.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 60,
      "num_heads": 56,
      "num_kv_heads": 8,
      "vocab_size": 64000,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/yi-34b-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Pixtral-12B-Base-2409",
      "total_params_b": 12.0,
      "active_params_b": 12.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 131072,
      "max_context_length": 1024000,
      "effective_context_length": 1024000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Pixtral-12B-Base-2409-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "QVQ-72B-Preview",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 128000,
      "effective_context_length": 128000,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/QVQ-72B-Preview-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "aya-vision-32b",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 40,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 256000,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/aya-vision-32b",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gemma-3-270m-it-torchao-FP8",
      "total_params_b": 0.26,
      "active_params_b": 0.26,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 640,
      "num_layers": 18,
      "num_heads": 4,
      "num_kv_heads": 1,
      "vocab_size": 262144,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gemma-3-270m-it-torchao-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.3-70B-Instruct-FP8-Block",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 68.9,
        "humaneval": 88.4,
        "gsm8k": 95.1,
        "math": 77.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.3-70B-Instruct-FP8-Block",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-70B",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 66.4,
        "humaneval": 80.5,
        "gsm8k": 95.1,
        "math": 68.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-70B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-3B-FP8-Dynamic",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 63.4,
        "mmlu_pro": 37.3,
        "humaneval": 61.6,
        "gsm8k": 77.7,
        "math": 48.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-3B-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "MiMo-V2-Flash",
      "total_params_b": 10.29,
      "active_params_b": 10.29,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 48,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 152576,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/MiMo-V2-Flash",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "c4ai-command-r-plus-08-2024",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 12288,
      "num_layers": 64,
      "num_heads": 96,
      "num_kv_heads": 8,
      "vocab_size": 256000,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 75.0,
        "mmlu_pro": null,
        "humaneval": 70.0,
        "gsm8k": 75.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/c4ai-command-r-plus-08-2024-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Hermes-3-Llama-3.1-70B",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 66.4,
        "humaneval": 80.5,
        "gsm8k": 95.1,
        "math": 68.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Hermes-3-Llama-3.1-70B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-Math-72B",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 4096,
      "effective_context_length": 4096,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-Math-72B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2-VL-72B",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 68.3,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2-VL-72B-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-4-Scout-17B-16E-dynamic",
      "total_params_b": 17.0,
      "active_params_b": 1.06,
      "is_moe": true,
      "num_experts": 16,
      "num_active_experts": 1,
      "hidden_dim": 5120,
      "num_layers": 48,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 202048,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-4-Scout-17B-16E-unsloth-dynamic-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Falcon-H1-34B-Instruct",
      "total_params_b": 34.0,
      "active_params_b": 34.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 72,
      "num_heads": 20,
      "num_kv_heads": 4,
      "vocab_size": 261120,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Falcon-H1-34B-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gpt-oss-safeguard-120b",
      "total_params_b": 120.0,
      "active_params_b": 3.75,
      "is_moe": true,
      "num_experts": 128,
      "num_active_experts": 4,
      "hidden_dim": 2880,
      "num_layers": 36,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 201088,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gpt-oss-safeguard-120b",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Jan-nano",
      "total_params_b": 3.22,
      "active_params_b": 3.22,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2560,
      "num_layers": 36,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Jan-nano",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-TNG-R1T2-Chimera-BF16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-TNG-R1T2-Chimera-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-8B-Instruct-FP8-Block",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-8B-Instruct-FP8-Block",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-V3.2-Exp",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 91.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-V3.2-Exp",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Starling-LM-7B-beta",
      "total_params_b": 7.0,
      "active_params_b": 7.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 32002,
      "max_context_length": 8192,
      "effective_context_length": 8192,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 2.4,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Starling-LM-7B-beta",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-Tulu-3-8B",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128264,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 69.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-Tulu-3-8B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Falcon-H1-1.5B-Deep-Instruct",
      "total_params_b": 1.5,
      "active_params_b": 1.5,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 1280,
      "num_layers": 66,
      "num_heads": 6,
      "num_kv_heads": 2,
      "vocab_size": 65537,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Falcon-H1-1.5B-Deep-Instruct",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "GLM-4.1V-9B-Thinking",
      "total_params_b": 9.0,
      "active_params_b": 9.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 40,
      "num_heads": 32,
      "num_kv_heads": 2,
      "vocab_size": 151552,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/GLM-4.1V-9B-Thinking",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "cogito-v2-preview-deepseek-671B-MoE-FP8",
      "total_params_b": 671.0,
      "active_params_b": 671.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 128815,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/cogito-v2-preview-deepseek-671B-MoE-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Olmo-3-32B-Think",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 100278,
      "max_context_length": 65536,
      "effective_context_length": 65536,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Olmo-3-32B-Think",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Kimi-Dev-72B",
      "total_params_b": 72.0,
      "active_params_b": 72.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Kimi-Dev-72B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen2.5-0.5",
      "total_params_b": 4.0,
      "active_params_b": 4.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 36,
      "num_heads": 16,
      "num_kv_heads": 2,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 45.0,
        "mmlu_pro": null,
        "humaneval": 30.5,
        "gsm8k": 36.0,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen2.5-0.5-bnb-4bit",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-235B-A22B-FP8",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 40960,
      "effective_context_length": 40960,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-235B-A22B-FP8",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "ERNIE-4.5-300B-A47B-PT",
      "total_params_b": 300.0,
      "active_params_b": 300.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 54,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 103424,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/ERNIE-4.5-300B-A47B-PT",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "cogito-v2-preview-llama-70B",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 55.5,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/cogito-v2-preview-llama-70B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "gpt-oss-safeguard-120b-BF16",
      "total_params_b": 120.0,
      "active_params_b": 3.75,
      "is_moe": true,
      "num_experts": 128,
      "num_active_experts": 4,
      "hidden_dim": 2880,
      "num_layers": 36,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 201088,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/gpt-oss-safeguard-120b-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "JanusCoder-14B",
      "total_params_b": 14.0,
      "active_params_b": 14.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 40,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 151936,
      "max_context_length": 32768,
      "effective_context_length": 32768,
      "domains": [
        "general",
        "code"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 12.2,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/JanusCoder-14B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-8B-FP8-Dynamic",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-8B-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "DeepSeek-R1-Zero-BF16",
      "total_params_b": 38.54,
      "active_params_b": 38.54,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 129280,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": 81.1,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/DeepSeek-R1-Zero-BF16",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "OpenReasoning-Nemotron-32B",
      "total_params_b": 32.0,
      "active_params_b": 32.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 5120,
      "num_layers": 64,
      "num_heads": 40,
      "num_kv_heads": 8,
      "vocab_size": 152064,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/OpenReasoning-Nemotron-32B",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "cogito-671b-v2.1",
      "total_params_b": 671.0,
      "active_params_b": 671.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 7168,
      "num_layers": 61,
      "num_heads": 128,
      "num_kv_heads": 128,
      "vocab_size": 128815,
      "max_context_length": 163840,
      "effective_context_length": 163840,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/cogito-671b-v2.1",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-1B-FP8-Block",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 49.3,
        "mmlu_pro": 24.7,
        "humaneval": 43.3,
        "gsm8k": 44.4,
        "math": 30.6,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-1B-FP8-Block",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-1B-FP8-Dynamic",
      "total_params_b": 1.0,
      "active_params_b": 1.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 2048,
      "num_layers": 16,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 49.3,
        "mmlu_pro": 24.7,
        "humaneval": 43.3,
        "gsm8k": 44.4,
        "math": 30.6,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-1B-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-8B-FP8-Block",
      "total_params_b": 8.0,
      "active_params_b": 8.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 32,
      "num_heads": 32,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 73.0,
        "mmlu_pro": 48.3,
        "humaneval": 72.6,
        "gsm8k": 84.5,
        "math": 51.9,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-8B-FP8-Block",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-70B-FP8-Block",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 66.4,
        "humaneval": 80.5,
        "gsm8k": 95.1,
        "math": 68.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-70B-FP8-Block",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.1-70B-FP8-Dynamic",
      "total_params_b": 70.0,
      "active_params_b": 70.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 8192,
      "num_layers": 80,
      "num_heads": 64,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 86.0,
        "mmlu_pro": 66.4,
        "humaneval": 80.5,
        "gsm8k": 95.1,
        "math": 68.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.1-70B-FP8-Dynamic",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Llama-3.2-3B-FP8-Block",
      "total_params_b": 3.0,
      "active_params_b": 3.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 3072,
      "num_layers": 28,
      "num_heads": 24,
      "num_kv_heads": 8,
      "vocab_size": 128256,
      "max_context_length": 131072,
      "effective_context_length": 131072,
      "domains": [
        "general"
      ],
      "capabilities": [],
      "benchmarks": {
        "mmlu": 63.4,
        "mmlu_pro": 37.3,
        "humaneval": 61.6,
        "gsm8k": 77.7,
        "math": 48.0,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Llama-3.2-3B-FP8-Block",
      "notes": "Auto-imported from Unsloth"
    },
    {
      "name": "Qwen3-VL-235B-A22B-Instruct-FP8",
      "total_params_b": 235.0,
      "active_params_b": 235.0,
      "is_moe": false,
      "num_experts": null,
      "num_active_experts": null,
      "hidden_dim": 4096,
      "num_layers": 94,
      "num_heads": 64,
      "num_kv_heads": 4,
      "vocab_size": 151936,
      "max_context_length": 262144,
      "effective_context_length": 262144,
      "domains": [
        "general",
        "vision"
      ],
      "capabilities": [
        "vision"
      ],
      "benchmarks": {
        "mmlu": null,
        "mmlu_pro": null,
        "humaneval": null,
        "gsm8k": null,
        "math": null,
        "bfcl": null
      },
      "hf_model_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-FP8",
      "notes": "Auto-imported from Unsloth"
    }
  ]
}